{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8462d94f",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23073449",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import re\n",
    "import spacy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45cb696",
   "metadata": {},
   "source": [
    "# NLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92072e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\") # spaCy model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85346d8c",
   "metadata": {},
   "source": [
    "# Extracting text from a PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "624d19d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page_num in range(doc.page_count):\n",
    "        page = doc.load_page(page_num)\n",
    "        text += page.get_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047ca51f",
   "metadata": {},
   "source": [
    "# PDF paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d07b0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_paths = [\n",
    "    \"/Users/amaanqureshi/Desktop/TB2/MSc Project/paper_1.pdf\",\n",
    "    \"/Users/amaanqureshi/Desktop/TB2/MSc Project/paper_2.pdf\",\n",
    "    \"/Users/amaanqureshi/Desktop/TB2/MSc Project/paper_3.pdf\",\n",
    "    \"/Users/amaanqureshi/Desktop/TB2/MSc Project/paper_4.pdf\",\n",
    "    \"/Users/amaanqureshi/Desktop/TB2/MSc Project/paper_5.pdf\",\n",
    "    \"/Users/amaanqureshi/Desktop/TB2/MSc Project/paper_6.pdf\",\n",
    "    \"/Users/amaanqureshi/Desktop/TB2/MSc Project/paper_7.pdf\",\n",
    "    \"/Users/amaanqureshi/Desktop/TB2/MSc Project/paper_8.pdf\",\n",
    "    \"/Users/amaanqureshi/Desktop/TB2/MSc Project/paper_9.pdf\",\n",
    "    \"/Users/amaanqureshi/Desktop/TB2/MSc Project/paper_10.pdf\",\n",
    "    '/Users/amaanqureshi/Desktop/TB2/MSc Project/paper_11.pdf',\n",
    "    '/Users/amaanqureshi/Desktop/TB2/MSc Project/paper_12.pdf',\n",
    "    '/Users/amaanqureshi/Desktop/TB2/MSc Project/paper_13.pdf',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693a4ad8",
   "metadata": {},
   "source": [
    "# Regex Function for polymers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfc12af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to identify potential polymer names using regex\n",
    "def identify_potential_polymer_names(text):\n",
    "    polymer_pattern = re.compile(\n",
    "        r'\\b(?:'\n",
    "        r'poly[a-zA-Z]*\\b|'                    # General pattern for synthetic polymers starting with 'poly'\n",
    "        r'[a-zA-Z]+poly[a-zA-Z]*\\b|'           # General pattern for polymers containing 'poly'\n",
    "        r'[a-zA-Z]*co[ -]?poly[a-zA-Z]*\\b|'    # Copolymers\n",
    "        r'polysaccharide\\b|'                   # Natural polymers: polysaccharides\n",
    "        r'cellulose\\b|'                        # Specific natural polymer\n",
    "        r'starch\\b|'                           # Specific natural polymer\n",
    "        r'glycogen\\b|'                         # Specific natural polymer\n",
    "        r'polyethylene\\b|'                     # Specific synthetic polymers\n",
    "        r'polypropylene\\b|'\n",
    "        r'polystyrene\\b|'\n",
    "        r'silicone\\b|'\n",
    "        r'nylon\\b|'\n",
    "        r'polyester\\b|'\n",
    "        r'acrylic\\b|'\n",
    "        r'aramid\\b|'\n",
    "        r'kevlar\\b|'\n",
    "        r'epoxy\\b|'\n",
    "        r'phenolic resin\\b|'\n",
    "        r'melamine\\b'\n",
    "        r')',\n",
    "        re.IGNORECASE\n",
    "    )\n",
    "    return polymer_pattern.findall(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdece641",
   "metadata": {},
   "source": [
    "# Properties Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "729d3609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to identify potential properties and their values\n",
    "def identify_properties_and_values(text):\n",
    "    property_pattern = re.compile(\n",
    "        r'\\b(?:melting point|boiling point|density|tensile strength|elastic modulus|thermal conductivity|glass transition temperature|hardness|viscosity|permeability|degradation temperature|solubility)\\b',\n",
    "        re.IGNORECASE\n",
    "    )\n",
    "    value_pattern = re.compile(\n",
    "        r'\\b\\d+\\.?\\d*\\s*(?:°C|°F|K|g/cm³|MPa|GPa|W/mK|Pa·s|m/s|mmHg|%)\\b',\n",
    "        re.IGNORECASE\n",
    "    )\n",
    "    properties = property_pattern.findall(text)\n",
    "    values = value_pattern.findall(text)\n",
    "    return list(zip(properties, values))\n",
    "\n",
    "# Function to refine and extract polymer names and properties using NLP and context\n",
    "def extract_polymer_properties(text):\n",
    "    potential_names = identify_potential_polymer_names(text)\n",
    "    polymer_data = {}\n",
    "\n",
    "    doc = nlp(text)\n",
    "\n",
    "    for token in doc:\n",
    "        if token.text in potential_names:\n",
    "            polymer_name = token.text.strip()\n",
    "            surrounding_text = text[max(0, token.idx - 100):min(len(text), token.idx + 100)]\n",
    "            properties_and_values = identify_properties_and_values(surrounding_text)\n",
    "\n",
    "            if polymer_name not in polymer_data:\n",
    "                polymer_data[polymer_name] = properties_and_values\n",
    "            else:\n",
    "                polymer_data[polymer_name].extend(properties_and_values)\n",
    "\n",
    "    return polymer_data\n",
    "\n",
    "# Function to convert extracted polymer properties into a DataFrame\n",
    "def convert_to_dataframe(polymer_data):\n",
    "    rows = []\n",
    "    for polymer, properties in polymer_data.items():\n",
    "        if polymer.lower() in [\"polymer\", \"polym\", \"polymers\"]:\n",
    "            continue  # Skip generic entries\n",
    "        if properties:\n",
    "            for prop, value in properties:\n",
    "                rows.append([polymer, prop, value])\n",
    "        else:\n",
    "            rows.append([polymer, \"\", \"\"])  # No properties\n",
    "    return pd.DataFrame(rows, columns=[\"Polymer\", \"Property\", \"Value\"])\n",
    "\n",
    "\n",
    "# Extract and process polymer properties from all PDFs\n",
    "all_data = []\n",
    "for pdf_path in pdf_paths:\n",
    "    text = extract_text_from_pdf(pdf_path)\n",
    "    polymer_properties = extract_polymer_properties(text)\n",
    "    all_data.append(convert_to_dataframe(polymer_properties))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8758aec5",
   "metadata": {},
   "source": [
    " # Saving to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba0e591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all data into a single DataFrame and save to CSV\n",
    "final_df = pd.concat(all_data, ignore_index=True)\n",
    "final_df.to_csv('Extracted_Polymer_Properties_Table.csv', index=False)\n",
    "\n",
    "# Print confirmation\n",
    "print(\"Polymer properties extracted and saved to 'Extracted_Polymer_Properties_Table.csv'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
